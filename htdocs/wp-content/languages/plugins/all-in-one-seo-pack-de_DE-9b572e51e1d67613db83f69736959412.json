{"translation-revision-date":"2024-02-27 02:14:08+0000","generator":"GlotPress\/4.0.0-beta.2","domain":"messages","locale_data":{"messages":{"":{"domain":"messages","plural-forms":"nplurals=2; plural=n != 1;","lang":"de"},"For some crawlers, encountering conflicting \"Crawl-delay\" might lead to unpredictable behavior.":["Bei einigen Crawlern kann das Aufeinandertreffen von widerspr\u00fcchlichen \"Crawl-Verz\u00f6gerungen\" zu unvorhersehbarem Verhalten f\u00fchren."],"Crawl-delay must be a number starting from 1.":["Crawl-Verz\u00f6gerung muss eine Zahl sein, die mit 1 beginnt."],"This site runs in a sub-directory. The robots.txt file must be located at the root of the website host to which it applies.":["Diese Website befindet sich in einem Unterverzeichnis. Die robots.txt-Datei muss sich im Root-Verzeichnis des Website-Hosts befinden, f\u00fcr den sie gilt."],"This rule overrides the default rule #%1$s%2$s.":["Diese Regel setzt die Standardregel #%1$s%2$s au\u00dfer Kraft."],"This rule is a duplicate of rule #%1$s%2$s.":["Diese Regel ist ein Duplikat von Regel #%1$s%2$s."],"This rule conflicts with rule #%1$s%2$s.%3$s":["Diese Regel steht im Widerspruch zu Regel #%1$s%2$s.%3$s"],"The network rule takes precedence.":["Die Netzwerkregel hat Vorrang."],"The \"Allow\" rule takes precedence.":["Die \u201eAllow\u201c-Regel hat Vorrang."],"Paste Robots.txt text":["Robots.txt-Text einf\u00fcgen"],"Invalid robots.txt URL.":["Ung\u00fcltige robots.txt-URL."],"Import Robots.txt":["Robots.txt importieren"],"Import from URL":["Importieren von URL"],"https:\/\/any-domain.com\/robots.txt":["https:\/\/any-domain.com\/robots.txt"],"from the network level":["von der Netzwerkebene"],"Equivalent to rule #%1$s%2$s. The trailing wildcard is ignored.":["\u00c4quivalent zu Regel #%1$s%2$s. Der Platzhalter am Ende wird ignoriert."],"Directive":["Direktive"],"Custom Robots.txt Preview":["Vorschau f\u00fcr individuelle robots.txt"],"Clean-param must start with at least one param which is optionally followed by one path.":["\u201eClean-param\u201c muss mit mindestens einem Parameter beginnen, dem optional ein Pfad folgt."],"No User-agent found in the content beginning.":["Kein User Agent am Anfang des Contents gefunden."],"These custom robots.txt rules will apply globally to your entire network. To adjust the robots.txt rules for an individual site, please visit the dashboard for that site directly and update the settings there.":["Diese individuellen robots.txt-Regeln gelten global f\u00fcr dein gesamtes Netzwerk. Um die robots.txt-Regeln f\u00fcr eine einzelne Website anzupassen, besuche bitte direkt das Dashboard dieser Website und aktualisiere die Einstellungen dort."],"These custom robots.txt rules will apply globally to your entire network. To adjust the robots.txt rules for an individual site, please choose it in the list above.":["Diese individuellen Robots.txt-Regeln gelten global f\u00fcr dein gesamtes Netzwerk. Um die robots.txt-Regeln f\u00fcr eine einzelne Website anzupassen, w\u00e4hle sie bitte in der Liste oben aus."],"Select Site":["Website ausw\u00e4hlen"],"%1$s Error":["%1$s Fehler","%1$s Fehler"],"It appears that your server is running on nginx, so the fix will most likely require adding the correct rewrite rules to our nginx configuration. %1$sCheck our documentation for more information%2$s.":["Dein Server scheint unter nginx zu laufen. Daher musst du zur Behebung sehr wahrscheinlich die korrekten Rewrite-Rules zu unserer nginx-Konfiguration hinzuf\u00fcgen. %1$sSchau dir unsere Dokumentation an, um weitere Informationen zu erhalten%2$s."],"It appears that your server is running on %1$s, so the fix should be as simple as checking the %2$scorrect .htaccess implementation on wordpress.org%3$s.":["Es scheint, dass dein Server auf %1$sl\u00e4uft, also sollte die L\u00f6sung so einfach sein wie die \u00dcberpr\u00fcfung der %2$skorrekten .htaccess Implementierung auf wordpress.org%3$s."],"It looks like you are missing the proper rewrite rules for the robots.txt file.":["Du scheinst die korrekten Rewrite-Rules f\u00fcr die robots.txt-Datei vergessen zu haben."],"This site is running in a sub-directory of your main site located at %1$s. Your robots.txt file should only appear in the root directory of that site.":["Diese Website l\u00e4uft in einem Unterverzeichnis deiner Haupt-Website unter %1$s. Deine robots.txt-Datei sollte nur im Stammverzeichnis dieser Website erscheinen."],"Import and Delete":["Importieren und l\u00f6schen"],"%1$s has detected a physical robots.txt file in the root folder of your WordPress installation. We recommend removing this file as it could cause conflicts with WordPress' dynamically generated one. %2$s can import this file and delete it, or you can simply delete it.":["%1$s hat eine physische robots.txt-Datei im Stammverzeichnis deiner WordPress-Installation entdeckt. Wir empfehlen dir, diese Datei zu entfernen, da sie zu Konflikten mit der von WordPress dynamisch erzeugten Datei f\u00fchren kann. %2$s kann diese Datei importieren und l\u00f6schen, oder du kannst sie einfach l\u00f6schen."],"Open Robots.txt":["Robots.txt \u00f6ffnen"],"Delete Rule":["Regel l\u00f6schen"],"Enable Custom Robots.txt":["Individuelle Robots.txt aktivieren"],"Just like WordPress, %1$s generates a dynamic file so there is no static file to be found on your server.  The content of the robots.txt file is stored in your WordPress database.":["Genau wie WordPress generiert auch %1$s eine dynamische Datei. Daher ist keine statische Datei auf deinem Server zu finden. Der Inhalt der robots.txt-Datei wird in deiner WordPress-Datenbank gespeichert."],"The robots.txt editor in %1$s allows you to set up a robots.txt file for your site that will override the default robots.txt file that WordPress creates. By creating a robots.txt file with %2$s you have greater control over the instructions you give web crawlers about your site.":["Der robots.txt.-Editor in %1$s erm\u00f6glicht dir, eine robots.txt-Datei f\u00fcr deine Website einzurichten, welche die standardm\u00e4\u00dfig von WordPress erzeugte robots.txt-Datei \u00fcberschreibt. Indem du eine robots.txt-Datei mit %2$s erstellst, hast du bessere Kontrolle \u00fcber die Anweisungen, die du Webcrawlern zu deiner Website gibst."],"Disallow":["Nicht zulassen"],"Allow":["Erlauben"],"Add Rule":["Regel hinzuf\u00fcgen"],"User Agent":["User Agent"],"Robots.txt Editor":["Robots.txt-Editor"]}},"comment":{"reference":"dist\/Lite\/assets\/js\/RobotsEditor.BH6KvYbf.js"}}